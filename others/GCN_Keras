#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu Jun 23 19:35:10 2022

@author: agustinzhang
"""

import pandas as pd
import numpy as np
import math
from stellargraph import StellarGraph
import random

df_node_total = pd.read_csv('df_node_total.csv')

def get_distance( point1, point2):
    return math.sqrt((point2[0]- point1[0])**2 + (point2[1]- point1[1])**2)

df_node_processed = df_node_total
for i in df_node_total.graph.unique():
    df_g = df_node_total[df_node_total['graph'] == i]
    df_no_PT = df_g[df_g.PT == 7]
    
    candidate_no_PT = list(set(df_no_PT.Candidate.values.tolist()))
    df_PT = df_g[df_g.PT != 7]
    num_PT = len(df_PT.PT.unique())
    remove = random.sample(candidate_no_PT, len(candidate_no_PT)-num_PT)
    
    index_remove = []
    for candidate in remove:
        index = df_g[df_g['Candidate'] == candidate].index.values.tolist()
        index_remove.extend(index)
        
    df_node_processed = df_node_processed.drop(index_remove)
    
    
    

graphs = []
graph_label = []
for i in df_node_processed.graph.unique():
    df_g = df_node_processed[df_node_processed['graph'] == i]
    for j in df_g.Candidate.unique():
        df_c = df_g[df_g['Candidate'] == j]
        node0 = [df_c['X'][df_c['Node'] == 'Node0'].values.tolist()[0] , df_c['Y'][df_c['Node'] == 'Node0'].values.tolist()[0]]
        node1 = [df_c['X'][df_c['Node'] == 'Node1'].values.tolist()[0] , df_c['Y'][df_c['Node'] == 'Node1'].values.tolist()[0]]
        node2 = [df_c['X'][df_c['Node'] == 'Node2'].values.tolist()[0] , df_c['Y'][df_c['Node'] == 'Node2'].values.tolist()[0]]
        node3 = [df_c['X'][df_c['Node'] == 'Node3'].values.tolist()[0] , df_c['Y'][df_c['Node'] == 'Node3'].values.tolist()[0]]
        node4 = [df_c['X'][df_c['Node'] == 'Node4'].values.tolist()[0] , df_c['Y'][df_c['Node'] == 'Node4'].values.tolist()[0]]
        
        
        #sum of distance to other 3 nodes
        feature_1 = get_distance(node1, node2)+ get_distance(node1, node3)+ get_distance(node1, node4)
        feature_2 = get_distance(node2, node1)+ get_distance(node2, node3)+ get_distance(node2, node4)
        feature_3 = get_distance(node3, node1)+ get_distance(node3, node2)+ get_distance(node3, node4)
        feature_4 = get_distance(node4, node1)+ get_distance(node4, node2)+ get_distance(node4, node3)
        
        square_node_data = pd.DataFrame(
            {"x": [1, 2, 3, 4], "y":[feature_1, feature_2, feature_3, feature_4]}, index = ["d", "b", "c", "a"])

        
        square_edges = pd.DataFrame(
            {"source": ['d', 'd', 'd', 'b', 'b'], "target":['b','c','a','c','a']})
        
        square_node_features = StellarGraph(square_node_data, square_edges)
        square_named_node_features = StellarGraph(
            {"corner": square_node_data}, {"line": square_edges})
        
        edge_feature1 = get_distance(node1, node2)
        edge_feature2 = get_distance(node1, node3)
        edge_feature3 = get_distance(node1, node4)
        edge_feature4 = get_distance(node2, node3)
        edge_feature5 = get_distance(node2, node4)
        
        square_edge_data = pd.DataFrame(
            {
                "source": ['d', 'd', 'd', 'b', 'b'],
                "target": ['b','c','a','c','a'],
                "Weights": [edge_feature1, edge_feature2, edge_feature3, edge_feature4, edge_feature5]})
        
        squared_named_features = StellarGraph(
            {"corner": square_node_data}, {"line": square_edge_data})
        
        graphs.append(squared_named_features)
        graph_label.append(df_c.PT.values.tolist()[0])
    graph_labels = pd.DataFrame()
    graph_labels['label'] = graph_label
    graph_labels = graph_labels.label
    

import pandas as pd
import numpy as np

import stellargraph as sg
from stellargraph.mapper import PaddedGraphGenerator
from stellargraph.layer import GCNSupervisedGraphClassification
from stellargraph import StellarGraph

from stellargraph import datasets

from sklearn import model_selection
from IPython.display import display, HTML

from tensorflow.keras import Model
from tensorflow.keras.optimizers import Adam, SGD
from tensorflow.keras.layers import Dense
from tensorflow.keras.losses import binary_crossentropy
from tensorflow.keras.callbacks import EarlyStopping
import tensorflow as tf
import matplotlib.pyplot as plt

graph_labels.value_counts()
graph_labels = pd.get_dummies(graph_labels, drop_first=False)

generator = PaddedGraphGenerator(graphs=graphs)


def create_graph_classification_model(generator):
    gc_model = GCNSupervisedGraphClassification(
        layer_sizes=[64, 64],
        activations=["relu", "relu"],
        generator=generator,
        dropout=0.5,
    )
    x_inp, x_out = gc_model.in_out_tensors()
    predictions = Dense(units=16, activation="relu")(x_out)
    predictions = Dense(units=8, activation="relu")(predictions)
    predictions = Dense(units=7, activation="softmax")(predictions)

    # Let's create the Keras model and prepare it for training
    model = Model(inputs=x_inp, outputs=predictions)
    model.compile(optimizer=SGD(0.001), loss=binary_crossentropy, metrics=["acc"])

    return model


epochs = 200  # maximum number of training epochs
folds = 20  # the number of folds for k-fold cross validation
n_repeats = 1  # the number of repeats for repeated k-fold cross validation

es = EarlyStopping(
    monitor="val_loss", min_delta=0, patience=25, restore_best_weights=True
)



def train_fold(model, train_gen, test_gen, es, epochs):
    history = model.fit(
        train_gen, epochs=epochs, validation_data=test_gen, verbose=0, callbacks=[es],
    )
    # calculate performance on the test data and return along with history
    test_metrics = model.evaluate(test_gen, verbose=0)
    test_acc = test_metrics[model.metrics_names.index("acc")]

    return history, test_acc

def get_generators(train_index, test_index, graph_labels, batch_size):
    train_gen = generator.flow(
        train_index, targets=graph_labels.iloc[train_index].values, batch_size=batch_size
    )
    test_gen = generator.flow(
        test_index, targets=graph_labels.iloc[test_index].values, batch_size=batch_size
    )

    return train_gen, test_gen






test_accs = []

stratified_folds = model_selection.RepeatedStratifiedKFold(
    n_splits=folds, n_repeats=n_repeats
).split(graph_labels, graph_labels)

for i, (train_index, test_index) in enumerate(stratified_folds):
    print(f"Training and evaluating on fold {i+1} out of {folds * n_repeats}...")
    train_gen, test_gen = get_generators(
        train_index, test_index, graph_labels, batch_size=30
    )

    model = create_graph_classification_model(generator)

    history, acc = train_fold(model, train_gen, test_gen, es, epochs)

    test_accs.append(acc)




print(
    f"Accuracy over all folds mean: {np.mean(test_accs)*100:.3}% and std: {np.std(test_accs)*100:.2}%"
)

          
plt.figure(figsize=(8, 6))
plt.hist(test_accs)
plt.xlabel("Accuracy")
plt.ylabel("Count")











